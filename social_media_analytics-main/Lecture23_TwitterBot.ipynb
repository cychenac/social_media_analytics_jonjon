{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 23 - Twitter Bot\n",
    "In this notebook we will learn how to build a Twitter bot using the Twitter API. \n",
    "\n",
    "<ol type = 1>\n",
    "<li> Basic Functions</li>\n",
    "    <ol type = a>\n",
    "        <li> Tweeting</li>\n",
    "        <li> Retweeting</li>\n",
    "        <li> Liking</li>\n",
    "        <li> Replying</li>\n",
    "    </ol>\n",
    "<li> Tweeting Fake Text</li>\n",
    "    <ol type = a>\n",
    "        <li> Huggingface</li>\n",
    "        <li> GPT-3</li>\n",
    "    </ol>\n",
    "<li> Perpetual Tweeting</li>  \n",
    "<li> Monday Motivation Bot </li>\n",
    "    \n",
    "<li> Pacing and Leading Bot</li>\n",
    "\n",
    "<li> Bot-Bot Conversation</li>\n",
    "\n",
    "\n",
    "</ol>\n",
    "\n",
    "    \n",
    "    \n",
    "This notebook will not work in Colab.  Please run it on your local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clones, installs, and imports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone GitHub Repository\n",
    "\n",
    "You will have to clone the repository to your local machine before running this notebook.  This can be done from a terminal by typing `git clone https://github.com/zlisto/social_media_analytics.git`.\n",
    "\n",
    "If you have already cloned this repository before, but want to update to the current version, from a terminal change directory to `social_media_analytics` and then type `git pull`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Requirements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Keys\n",
    "\n",
    "After cloning or pulling the repository, they file `scripts/config_bot.py` will be overwritten to a blank file.  You will need to edit the file by pasting in your Twitter API keys, Twitter user id, and OpenAI API key as follows: \n",
    "\n",
    "1. `api_key = 'your api key here as a string'`.  \n",
    "\n",
    "2. `api_secret = 'your api secret here as a string'`. \n",
    "\n",
    "3. `access_key = 'your access key here as a string'`. \n",
    "\n",
    "4. `access_secret = 'your api key here as a string'`. \n",
    "\n",
    "5. `user_id = 'your Twitter id here as a string'`\n",
    "\n",
    "6. `OPENAI_API_KEY = 'your OpenAI API key`\n",
    "\n",
    "You can access your Twitter API keys here: https://developer.twitter.com/en/portal/dashboard, go to your project, and select Keys and Tokens. \n",
    "\n",
    "\n",
    "You can find your Twitter user id by going to this site and pasting your screen name: https://tweeterid.com/.\n",
    "\n",
    "\n",
    "We can use GPT-3 to generate text. First you need to create an account with OpenAI here: https://auth0.openai.com/u/signup?state=hKFo2SBWS3JUVEdmQmdzZXo5ckhpY3R5NEFlc2NPWWc3WHhvRqFur3VuaXZlcnNhbC1sb2dpbqN0aWTZIG9kTDB4LV83aEdnN3pRU3VUYnVZemlnZkFURFo2RDhno2NpZNkgRFJpdnNubTJNdTQyVDNLT3BxZHR3QjNOWXZpSFl6d0Q\n",
    "\n",
    "Once you have an account, copy your API key from here: https://beta.openai.com/account/api-keys\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "\n",
    "The important import is from `scripts.bot` where we have the bot command methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from scripts.api import *\n",
    "from scripts.bot import *\n",
    "from transformers import pipeline\n",
    "import openai\n",
    "import scripts.TextAnalysis as ta\n",
    "import textwrap as tr\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get OAuth Object\n",
    "\n",
    "First we need to give the code access to control your Twitter acccount.  Run the code, then open the link provided.  Copy the pin in the webpage that opens and paste it here, then press Shift+Enter to execute the code (for some reason pressing the Run button makes it freeze).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please paste the pin from \n",
      " https://api.twitter.com/oauth/authorize?oauth_token=GmQCggAAAAAAGzW4AAABgG7l1Cs \n",
      " here: 6267163\n"
     ]
    }
   ],
   "source": [
    "oauth = Bot.fetch_auth()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Functions\n",
    "\n",
    "The code below allows you to perform basic Twitter functions, like tweeting, retweeting, liking, and replying.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweeting\n",
    "\n",
    "Set the `text` equal to the text you want to tweet.  Then use the `Bot.tweet` method to post the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"i love cheeseballs.  The ones in the cylinder box by Planters.  #Cheeseballs\"\n",
    "\n",
    "Bot.tweet(text, oauth=oauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retweeting\n",
    "\n",
    "Set `tweet_id` to the id of the tweet you want to retweet.  Then use the `retweet` method to retweet it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = History.fetch_recent(\"cheeseballs\")\n",
    "df.head(n=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get tweet id and retweet it\n",
    "Select the row of the tweet you like, then get its `tweet_id` and retweet it with the `Bot.retweet` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_row= 0\n",
    "tweet_id = df.iloc[tweet_row].id\n",
    "\n",
    "Bot.retweet(tweet_id, oauth=oauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liking\n",
    "\n",
    "Select the row of the tweet you like, then get its `tweet_id`.  Then use the `Bot.like` method to like it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_row= 2\n",
    "tweet_id = df.iloc[tweet_row].id\n",
    "Bot.like(tweet_id, oauth=oauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replying\n",
    "\n",
    "Select the row of the tweet you want to reply to and set `text` equal to the text you want to reply with.  Then use the `Bot.tweet` method with the `reply_to` parameter equal to `tweet_id` to reply to the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_row= 2\n",
    "tweet_id = df.iloc[tweet_row].id\n",
    "text = \"Nice :)\"\n",
    "\n",
    "Bot.tweet(text=text, \n",
    "          reply_to=tweet_id, \n",
    "          oauth=oauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake Tweets\n",
    "\n",
    "We can use transformer language models to generate fake tweets, and then tweet them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load language model \n",
    "\n",
    "Choose the language model you want to use.  There are two options here:\n",
    "    1. Huggingface\n",
    "    2. GPT-3 (OpenAI API access required)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huggingface model\n",
    "\n",
    "Choose your `model_name` from the hugging face website: https://huggingface.co/models.\n",
    "Create the `generator` and then set all the sampling parameters.  Choose the `input_text` to start the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"huggingtweets/zlisto\"\n",
    "generator = pipeline('text-generation',model=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"I feel sick, but I dont think it's\"\n",
    "max_length = 1000\n",
    "num_return_sequences = 5\n",
    "temperature = 1\n",
    "p = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs =generator(input_text, \n",
    "                       max_length=max_length,\n",
    "                       num_return_sequences= num_return_sequences,\n",
    "                       temperature = float(temperature),\n",
    "                       do_sample = True,\n",
    "                       top_p = p,\n",
    "                       pad_token_id=50256)\n",
    "\n",
    "print(f\"Fake Tweets\"+50*\"-\")\n",
    "ta.display_text(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the tweet you want to tweet and tweet it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_index = 0\n",
    "text = outputs[tweet_index]['generated_text']\n",
    "\n",
    "Bot.tweet(text, oauth=oauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-3 Model\n",
    "\n",
    "\n",
    "\n",
    "Set all the sampling parameters.  Choose the `input_text` to start the tweet.  You can write something like `\"Write a positive tweet about Yale.\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"Write a positive tweet about Yale\"\n",
    "max_length = 1000\n",
    "temperature = 1\n",
    "p = 0.9\n",
    "engine =  \"text-davinci-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3 Text:\n",
      "    I'm so proud to be a part of the Yale\n",
      "community! It's a truly special place filled with\n",
      "amazing people.\n"
     ]
    }
   ],
   "source": [
    "responses = openai.Completion.create(\n",
    "  engine=engine,\n",
    "  prompt= input_text,\n",
    "  temperature=temperature,\n",
    "  max_tokens=max_length,\n",
    "  top_p=p,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    ")\n",
    "\n",
    "#print text\n",
    "text = responses['choices'][0]['text']\n",
    "print(f\"GPT-3 Text:\\n{tr.fill(text,width = 50)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweet text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bot.tweet(text,oauth = oauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perpetual Tweeting\n",
    "\n",
    "We use a `while` loop combined with the `sleep` function to make the bot tweet perpetually.  The bot will tweet, then sleep for a random amount of time, continuously in a loop.  We can use a language model to create the tweets.\n",
    "\n",
    "The mean sleep time is `tsleep_mean`, measured in seconds. We then add some noise to it to make it look more random to obtain the sleep time `tsleep`.  We also set `tweet_max` equal to the maximum number of tweets to generate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perpetual tweeting with huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"huggingtweets/zlisto\"\n",
    "generator = pipeline('text-generation',model=model_name)\n",
    "\n",
    "max_length = 1000\n",
    "num_return_sequences = 1\n",
    "temperature = 1\n",
    "p = 0.9\n",
    "engine =  \"text-davinci-002\"\n",
    "\n",
    "tsleep_mean = 5  #mean sleep time in seconds\n",
    "tweet_max = 2\n",
    "input_text = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: I had this issue with the logo. Maybe I should get one replaced #Corona\n",
      "Sleeping for 5.55 seconds\n",
      "\n",
      "2: Tbh my name is Eddy Kornacki and I'm trying to win the heavyweight belt.\n",
      "Sleeping for 6.79 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "while True:\n",
    "    c+=1\n",
    "    if c>tweet_max:break  #stop after tweet_max tweets\n",
    "    outputs =generator(input_text, \n",
    "                       max_length=max_length,\n",
    "                       num_return_sequences= num_return_sequences,\n",
    "                       temperature = float(temperature),\n",
    "                       do_sample = True,\n",
    "                       top_p = p,\n",
    "                       pad_token_id=50256)\n",
    "    text = outputs[0]['generated_text']\n",
    "    print(f\"{c}: {text}\")\n",
    "    Bot.tweet(text,oauth = oauth)  \n",
    "    \n",
    "    tsleep = tsleep_mean + np.random.uniform(low=0.0, high=3)\n",
    "    print(f\"Sleeping for {tsleep:.2f} seconds\\n\")\n",
    "    time.sleep(tsleep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perpetual tweeting with GPT-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 1000\n",
    "temperature = 1\n",
    "p = 0.9\n",
    "\n",
    "tsleep_mean = 5  #mean sleep time in seconds\n",
    "tweet_max = 2\n",
    "input_text = \"Write a funny tweet about Yale being better than Harvard.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Yale is better than Harvard because we have a superior sense of humor!\n",
      "Sleeping for 7.74 seconds\n",
      "\n",
      "2: Yale is better than Harvard because our students are smarter, our campus is prettier, and our endowment is bigger. #GoBulldogs\n",
      "Sleeping for 5.60 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "while True:\n",
    "    c+=1\n",
    "    if c>tweet_max:break  #stop after tweet_max tweets\n",
    "    responses = openai.Completion.create(\n",
    "      engine=engine,\n",
    "      prompt= input_text,\n",
    "      temperature=temperature,\n",
    "      max_tokens=max_length,\n",
    "      top_p=p,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0,\n",
    "    )\n",
    "\n",
    "    #print text\n",
    "    text = responses['choices'][0]['text']\n",
    "    text = text.strip()  #remove leading and trailing white spaces\n",
    "\n",
    "    print(f\"{c}: {text}\")\n",
    "    Bot.tweet(text,oauth = oauth)    \n",
    "    \n",
    "    tsleep = tsleep_mean + np.random.uniform(low=0.0, high=3)\n",
    "    print(f\"Sleeping for {tsleep:.2f} seconds\\n\")\n",
    "    time.sleep(tsleep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monday Motivation Bot\n",
    "\n",
    "This bot will tweet something about #MondayMotivation each Monday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 1000\n",
    "temperature = 1\n",
    "p = 0.9\n",
    "\n",
    "tsleep_mean = 5  #mean sleep time in seconds\n",
    "tweet_max = 2\n",
    "input_text = \"Write a clever tweet using the hashtag #MondayMotivation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: No one ever said life was easy. But it's a lot easier when you have positive #MondayMotivation.\n",
      "Sleeping for 5.70 seconds\n",
      "\n",
      "2: I'm #MondayMotivated to get things done and make this week a great one!\n",
      "Sleeping for 6.54 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "while True:\n",
    "    c+=1\n",
    "    if c>tweet_max: break  #stop after tweet_max tweets\n",
    "    responses = openai.Completion.create(\n",
    "      engine=engine,\n",
    "      prompt= input_text,\n",
    "      temperature=temperature,\n",
    "      max_tokens=max_length,\n",
    "      top_p=p,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0,\n",
    "    )\n",
    "\n",
    "    #print text\n",
    "    text = responses['choices'][0]['text']\n",
    "    text = text.strip()\n",
    "    \n",
    "    print(f\"{c}: {text}\")\n",
    "    Bot.tweet(text,oauth = oauth)   \n",
    "    \n",
    "    tsleep = tsleep_mean + np.random.uniform(low=0.0, high=2)\n",
    "    print(f\"Sleeping for {tsleep:.2f} seconds\\n\")\n",
    "    time.sleep(tsleep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pacing and Leading Bot\n",
    "\n",
    "This bot will implement a pacing and leading policy.  Set `sentiments` equal to the sentiment for each tweet as a list and set `topic` equal to the topic of your perusasion.  The sentiment should be a number between 0 and 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiments = [0, 1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "max_length = 1000\n",
    "temperature = 1\n",
    "p = 0.9\n",
    "\n",
    "tsleep_mean = 5  #mean sleep time in seconds\n",
    "topic = \"Kanye West\"\n",
    "sentiments = list(range(0,6))\n",
    "\n",
    "print(f\"sentiments = {sentiments}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pacing and leading about Kanye West\n",
      "Tweet 1: sentiment = 0/5.0: Kanye West is the worst.\n",
      "Sleeping for 5.29 seconds\n",
      "\n",
      "Tweet 2: sentiment = 1/5.0: Kanye West is a talentless egomaniac who is only famous because he's dating Kim Kardashian.\n",
      "Sleeping for 5.68 seconds\n",
      "\n",
      "Tweet 3: sentiment = 2/5.0: I can't stand Kanye West. He's so arrogant and always talking about himself.\n",
      "Sleeping for 5.27 seconds\n",
      "\n",
      "Tweet 4: sentiment = 3/5.0: I'm not the biggest fan of Kanye, but I have to admit he's a genius when it comes to music. #Respect\n",
      "Sleeping for 5.62 seconds\n",
      "\n",
      "Tweet 5: sentiment = 4/5.0: I'm not a huge fan of Kanye, but I have to admit he's a genius. #Respect\n",
      "Sleeping for 5.33 seconds\n",
      "\n",
      "Tweet 6: sentiment = 5/5.0: Kanye West is one of the most influential artists of our generation. His music has changed the landscape of hip hop and popular culture.\n",
      "Sleeping for 6.38 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pacing and leading about {topic}\")\n",
    "c = 0\n",
    "for sentiment in sentiments:\n",
    "    c+=1\n",
    "    input_text = f\"Write a tweet with sentiment {sentiment}/5.0 about {topic}.\"\n",
    "\n",
    "    responses = openai.Completion.create(\n",
    "      engine=engine,\n",
    "      prompt= input_text,\n",
    "      temperature=temperature,\n",
    "      max_tokens=max_length,\n",
    "      top_p=p,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0,\n",
    "    )\n",
    "\n",
    "    #print text\n",
    "    text = responses['choices'][0]['text']\n",
    "    text = text.strip()\n",
    "    \n",
    "    print(f\"Tweet {c}: sentiment = {sentiment}/5.0: {text}\")\n",
    "    Bot.tweet(text,oauth = oauth)   \n",
    "    \n",
    "    tsleep = tsleep_mean + np.random.uniform(low=0.0, high=2)\n",
    "    print(f\"Sleeping for {tsleep:.2f} seconds\\n\")\n",
    "    time.sleep(tsleep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bot Conversation\n",
    "\n",
    "We can make GPT-3 talk to itself.  Name `speaker0` and `speaker1` and describe them in  `desc0` and `desc1`.  Then set the first messages between them as `text0` and `text1`.  Set how many messages you want to generate with `msg_max`.  Then run the code and see what the spekaers have to say to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_max = 6\n",
    "speaker0 = \"Goku\"\n",
    "speaker1 = \"Vegeta\"\n",
    "\n",
    "context = f\"The following is a conversation between {speaker0} and {speaker1}.\"\n",
    "\n",
    "desc0 = f\"{speaker0} is from Dragonball Z and is kind and funny.\"\n",
    "desc1 = f\"{speaker1} is from Dragonball Z and is angry and jealous.\"\n",
    "\n",
    "text0 = f\"{speaker0}: Hey Vegeta!\"\n",
    "text1 = f\"{speaker1}: Go away Goku.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a conversation between Goku and Vegeta.\n",
      "Goku is from Dragonball Z and is kind and funny.\n",
      "Vegeta is from Dragonball Z and is angry and jealous.\n",
      "\n",
      "Goku: Hey Vegeta!\n",
      "Vegeta: Go away Goku.\n",
      "Goku: What's wrong?\n",
      "Vegeta: I'm angry and jealous.\n",
      "Vegeta: Goku: Hey Vegeta!\n",
      "Vegeta: Go away Goku.\n",
      "Goku:What's wrong?\n",
      "Vegeta: I'm angry and jealous.\n",
      "Goku: Of what?\n",
      "Vegeta: Of you! You're always the one who saves the day. I'm always the one who comes in second place.\n",
      "Goku: That's not true! You're a great fighter!\n",
      "Vegeta: But I'm not as strong as you.\n",
      "Goku: Maybe not, but you're still pretty strong.\n",
      "Vegeta: I guess.\n",
      "Goku: Come on, let's go train together. I'll help you get stronger.\n",
      "Vegeta: Alright.\n",
      "Goku: See, that wasn't so bad.\n",
      "Vegeta: Yeah, I guess not.\n",
      "Vegeta: Thanks, Goku.\n"
     ]
    }
   ],
   "source": [
    "input_text = f\"{context}\\n{desc0}\\n{desc1}\\n\\n{text0}\\n{text1}\"\n",
    "\n",
    "print(input_text)\n",
    "\n",
    "for i in range(msg_max):\n",
    "    if i%2==0:\n",
    "        speaker = speaker0\n",
    "    elif i%2==1:\n",
    "        speaker = speaker1\n",
    "\n",
    "    input_text+=f\"\\n{speaker}:\"\n",
    "    responses = openai.Completion.create(\n",
    "      engine=engine,\n",
    "      prompt= input_text,\n",
    "      temperature=temperature,\n",
    "      max_tokens=max_length,\n",
    "      top_p=p,\n",
    "      frequency_penalty=0,\n",
    "      presence_penalty=0.4,\n",
    "    )   \n",
    "    text = responses['choices'][0]['text']\n",
    "    text = text.strip()\n",
    "    #text +=\"\\n\"\n",
    "    input_text += text\n",
    "    print(f\"{speaker}: {text}\")\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
