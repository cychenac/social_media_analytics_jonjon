{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 2 - Introduction to Social Media Analytics with Python\n",
    "\n",
    "In this notebook we will learn the basics for analyzing  social media data with Python.  We will study tweets collected by keyword, tweets collected by user, and user profiles.  Some of the skills you will learn include searching and sorting dataframes and making bar and scatter plots.  For more details on the dataframe functions used in this notebook, you can look here: https://pandas.pydata.org/docs/index.html\n",
    "\n",
    "This notebook can be opened in Colab \n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zlisto/social_media_analytics/blob/main/Lecture02_BasicSocialMediaDataAnalysis.ipynb)\n",
    "\n",
    "Before starting, select \"Runtime->Factory reset runtime\" to start with your directories and environment in the base state.\n",
    "\n",
    "If you want to save changes to the notebook, select \"File->Save a copy in Drive\" from the top menu in Colab.  This will save the notebook in your Google Drive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clone GitHub Repository\n",
    "This will clone the repository to your machine.  This includes the code and data files.  Then change into the directory of the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/zlisto/social_media_analytics\n",
    "\n",
    "import os\n",
    "os.chdir(\"social_media_analytics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Requirements \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "\n",
    "We import the packages we are going to use.  A package contains several useful functions that make our life easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scripts.api import *\n",
    "\n",
    "\n",
    "#this option makes it so tweets display nicely in a dataframe\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keyword Tweets\n",
    "\n",
    "We begin with a set of tweets that contain a specific hashtag.  These were found using Twitter's Search API.  The tweets were saved in a table in a database file.  The filename of the database is stored in the variable `fname_db`.  The table's name is `\"keyword_tweets\"`.  Each row\n",
    "of this table is a tweet with many columns of information.  The most important columns are \"created_at,screen_name,text\".  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Keyword Tweets\n",
    "We load the tweets from the database using the `DB.fetch` function. The tweets are loaded into a variable called **df** which is a *dataframe*.  Dataframes store each tweet as a row and let us access the rows and columns easily.  We will use dataframes a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename of database\n",
    "fname_db = \"data/lecture_02\"  #database filenmae\n",
    "\n",
    "df = DB.fetch(table_name='keyword_tweets', path=fname_db)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the tweets using head() function\n",
    "After we load the tweets in **df**, we look at the first few tweets using the *head* function.  We can specify how many rows to show using the *n* parameter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Columns of Dataframe\n",
    "\n",
    "Sometimes we just want to look at a few columns of the dataframe.  We can do this by putting the names of the columns we want into a *list*.  In Python, lists have the format `[item_1,item_2,...,item_n]`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col = ['screen_name','text']\n",
    "df[ col].head(n=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Rows of Dataframe\n",
    "\n",
    "The `head` function will give the first few rows of the dataframe.  We can use the `sample` function to randomly sample a fixed number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ ['screen_name','text']].sample(n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for Tweets Containing Keywords\n",
    "\n",
    "We can search for tweets in the dataframe which contains a specific keyword.  We do this with the `contains` function.  This function takes the keyword as input in the form of a string (this means you put the word inside quotes).  It also has a parameter `case` which is `True` if you want to match the case of the keyword.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'eminem'\n",
    "\n",
    "df[df.text.str.contains(keyword, case = False)][['screen_name','text']].sample(n=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Column to Dataframe\n",
    "\n",
    "We can add a column to the dataframe to make data analysis easier.  Let's add a column called `\"has_keyword\"` which is `True` if the tweet has the word \"eminem\".  This can be done by doing `df[\"has_keyword\"] = column you want to add`.  In our case, the column we want to add is given by `df.text.str.contains(keyword, case = False)`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'eminem'\n",
    "\n",
    "df['has_keyword'] = df.text.str.contains(keyword, case = False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Rows in Dataframe\n",
    "\n",
    "We can use the `len` function to find out how many rows a dataframe has.  Let's find out how many tweets contain our keyword, and then print out the result. We can use the column we just created for this to make the code cleaner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keyword = df[df['has_keyword']==True][['screen_name','text']] \n",
    "n_keyword = len(df_keyword)\n",
    "\n",
    "print(f\"There are {n_keyword} tweets that contain the keyword '{keyword}' \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort Rows By Column Values\n",
    "We can sort a dataframe's rows by the values in a column with the `sort_value` function.  It takes as input a list of columns, and an optional parameter `ascending` which can be `True` or `False`. \n",
    "\n",
    "Let's sort the tweets in order of decreasing `retweet_count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['retweet_count','screen_name','text']].sort_values(by = ['retweet_count'], ascending = False).head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics of Columns\n",
    "\n",
    "There are built-in functions in a dataframe to calculate many different statistis, such as `mean`, `median`, `variance`, `std`, and `quantile`.  For `quantile` we need to set the quantile we want in the variable `q`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df['retweet_count'].mean()\n",
    "med = df['retweet_count'].median()\n",
    "std = df['retweet_count'].std()\n",
    "q = 0.9\n",
    "quant = df['retweet_count'].quantile(q)\n",
    "\n",
    "print(f\"Retweet count\\n\\tmean = {mean:.2f}\\n\\tmedian = {med:.2f}\\n\\tst. dev. = {std}\\n\\t{q:.2f} quantile = {quant}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Profiles\n",
    "\n",
    "We next look at a table of user profiles.  These are in the same database in the table `users`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load User Profiles\n",
    "We load the user profiles from the database using the `DB.fetch` function. The profiles are loaded into a dataframe called **df_u**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename of database\n",
    "fname_db = \"data/lecture_02\"  #database filenmae\n",
    "\n",
    "df_u = DB.fetch(table_name='users', path=fname_db)\n",
    "\n",
    "\n",
    "print(f\"We have {len(df_u)} user profiles\")\n",
    "df_u.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Graph of Follower Count\n",
    "\n",
    "We can make a bar graph of the follower count of the users.  To make the plot, we use the `barplot` function in the *seaborn* package.  Details on the seaborn package can be found here: https://seaborn.pydata.org/#\n",
    "\n",
    "To use `barplot`, we need to input the `data`, which is the dataframe, `x`, which is the name of the column for the x-axis, and `y`, which is the name of the column for the y-axis.  There are many other functions that let us edit the plot to make it look nice.  These are from the *matplotlib* package.  One parameter is the `color` parameter.  A complete list of colors is found here: https://matplotlib.org/stable/gallery/color/named_colors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,6))\n",
    "sns.barplot(data = df_u, x = 'screen_name', y = 'followers_count',\n",
    "           color = 'crimson')\n",
    "plt.xlabel('Screen name', fontsize = 16)\n",
    "plt.ylabel('Followers count', fontsize = 16)\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.title(\"Twitter Users\", fontsize = 20)\n",
    "plt.grid()\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Tweets\n",
    "\n",
    "The tweets here were collected from the Twitter timelines of a set of users.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load User Tweets\n",
    "\n",
    "The tweets are in the same database in a table called `\"user_tweets\"`.  We can load them with the `DB.fetch` function into a dataframe called `df_ut` (ut for user tweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename of database\n",
    "fname_db = 'data/lecture_02'\n",
    "\n",
    "df_ut = DB.fetch(table_name = 'user_tweets', path = fname_db)\n",
    "\n",
    "print(f\"We have {len(df_ut)} user tweets\")\n",
    "df_ut.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Tweets\n",
    "\n",
    "We can group the tweets using the `groupby` function.  Once we group the tweets, we can calculate apply other functions to tweets in the group, such as `mean`.  We do this for the `retweet_count` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ut.groupby('screen_name').mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barplot Retweet Count of Groups\n",
    "\n",
    "We can make a barplot of a column value on the y-axis, and the group on the x-axis.  Seaborn knows to group together tweets in the same group, and plot the mean value along with error bars. In this case, we will plot `retweet_count` on the y-axis, and the groups are the `screen_name` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,6))\n",
    "sns.barplot(data = df_ut, x = 'screen_name', y = 'retweet_count', color = \"blue\")\n",
    "plt.xlabel('Screen name', fontsize = 16)\n",
    "plt.ylabel('Retweet count', fontsize = 16)\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.title(\"Twitter Users\", fontsize = 20)\n",
    "plt.grid()\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subplots\n",
    "\n",
    "We can plot two figures side by side using the `subplot` function.  You need to specify the number of rows and columns in your subplot grid, and specify which grid box the plot goes in.  It is something like this: `subplot(rows, columns, box_number)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (16,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "sns.barplot(data = df_u, x = 'screen_name', y = 'followers_count',\n",
    "           color = 'crimson')\n",
    "plt.xlabel('Screen name', fontsize = 16)\n",
    "plt.ylabel('Followers count', fontsize = 16)\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.title(\"Twitter Users\", fontsize = 20)\n",
    "plt.grid()\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.barplot(data = df_ut, x = 'screen_name', y = 'retweet_count', color = \"blue\")\n",
    "plt.xlabel('Screen name', fontsize = 16)\n",
    "plt.ylabel('Retweet count', fontsize = 16)\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.title(\"Twitter Users\", fontsize = 20)\n",
    "plt.grid()\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Retweet Count of Tweets Containing Different Keywords\n",
    "\n",
    "We can compare the retweet count of tweets that contain a keyword versus those that do not.  We do this by adding a column to the dataframe called `has_keyword` that is `True` if the tweet has the word.  We can then plot the retweet count grouped by screen name, and separate within the group those where `has_keyword` is `True` and `False`.  We use the `hue` parameter for this in-group separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'drops'\n",
    "\n",
    "df_ut['has_keyword'] = df_ut.text.str.contains(keyword, case = False)\n",
    "\n",
    "fig = plt.figure(figsize = (8,6))\n",
    "sns.barplot(data = df_ut, x = 'screen_name', y = 'retweet_count',\n",
    "                hue = 'has_keyword')\n",
    "plt.xlabel('Screen name',fontsize  = 14)\n",
    "plt.ylabel('Retweet count',fontsize  = 14)\n",
    "plt.title(f\"Keyword ={keyword}\",fontsize = 18)\n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe Groups\n",
    "\n",
    "We can group the tweets by `screen_name` and `has_keyword` using the `groupby` function.  Then we can summarize the statistics of the groups in a dataframe by using the `describe` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Keyword is {keyword}\")\n",
    "df_ut.groupby(['screen_name','has_keyword'])[['retweet_count']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Notebook to HTML\n",
    "\n",
    "This last line will let you save the notebook and all of its outputs to an HTML file.  You can download this file to your computer from Colab and then print it to a PDF using ctrl+P."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to html <notebook_path>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
